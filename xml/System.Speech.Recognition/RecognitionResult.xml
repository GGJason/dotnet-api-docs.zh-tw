<Type Name="RecognitionResult" FullName="System.Speech.Recognition.RecognitionResult">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="58dc7fd01cd9580179bf403a5d3c0b372c8b28ee" />
    <Meta Name="ms.sourcegitcommit" Value="d31dc2ede16f6f7bc64e90d9f897ff54c4e3869b" />
    <Meta Name="ms.translationtype" Value="HT" />
    <Meta Name="ms.contentlocale" Value="zh-TW" />
    <Meta Name="ms.lasthandoff" Value="04/03/2018" />
    <Meta Name="ms.locfileid" Value="30528862" />
  </Metadata>
  <TypeSignature Language="C#" Value="public sealed class RecognitionResult : System.Speech.Recognition.RecognizedPhrase, System.Runtime.Serialization.ISerializable" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi serializable sealed beforefieldinit RecognitionResult extends System.Speech.Recognition.RecognizedPhrase implements class System.Runtime.Serialization.ISerializable" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognitionResult" />
  <TypeSignature Language="VB.NET" Value="Public NotInheritable Class RecognitionResult&#xA;Inherits RecognizedPhrase&#xA;Implements ISerializable" />
  <TypeSignature Language="C++ CLI" Value="public ref class RecognitionResult sealed : System::Speech::Recognition::RecognizedPhrase, System::Runtime::Serialization::ISerializable" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Speech.Recognition.RecognizedPhrase</BaseTypeName>
  </Base>
  <Interfaces>
    <Interface>
      <InterfaceName>System.Runtime.Serialization.ISerializable</InterfaceName>
    </Interface>
  </Interfaces>
  <Attributes>
    <Attribute>
      <AttributeName>System.Diagnostics.DebuggerDisplay("{DebuggerDisplayString ()}")</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <summary>包含<see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />或<see cref="T:System.Speech.Recognition.SpeechRecognizer" />的執行個體所辨認的輸入的詳細資訊。</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 此類別衍生自<xref:System.Speech.Recognition.RecognizedPhrase>並提供詳細的語音辨識，包括下列資訊：  
  
-   <xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A>屬性參考<xref:System.Speech.Recognition.Grammar>辨識器用來識別語音。  
  
-   <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A>屬性包含片語的正規化的文字。 如需文字正規化的詳細資訊，請參閱<xref:System.Speech.Recognition.ReplacementText>。  
  
-   <xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A>屬性參考包含在結果中語意資訊。 語意資訊是索引鍵名稱和相關聯的語意資料的字典。  
  
-   <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>屬性包含的集合<xref:System.Speech.Recognition.RecognizedPhrase>代表音訊的輸入的其他候選解譯的物件。 如需詳細資訊，請參閱 <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>。  
  
-   <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A>屬性包含已排序的集合<xref:System.Speech.Recognition.RecognizedWordUnit>代表每個物件，辨識輸入中的文字。 每個<xref:System.Speech.Recognition.RecognizedWordUnit>包含顯示格式、 語彙格式，以及相對應的文字的發音資訊。  
  
 某些成員<xref:System.Speech.Recognition.SpeechRecognitionEngine>， <xref:System.Speech.Recognition.SpeechRecognizer>，和<xref:System.Speech.Recognition.Grammar>類別可以產生<xref:System.Speech.Recognition.RecognitionResult>。 如需詳細資訊，請參閱下列方法和事件。  
  
-   方法和事件的<xref:System.Speech.Recognition.SpeechRecognitionEngine>類別：  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>  
  
-   方法和事件的<xref:System.Speech.Recognition.SpeechRecognizer>類別：  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>  
  
    -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>  
  
-   <xref:System.Speech.Recognition.Grammar.SpeechRecognized>事件<xref:System.Speech.Recognition.Grammar>類別。  
  
 如需辨識事件的詳細資訊，請參閱[使用語音辨識事件](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)。  
  
   
  
## Examples  
 下列範例示範的處理常式`SpeechRecognized`事件<xref:System.Speech.Recognition.SpeechRecognitionEngine>或<xref:System.Speech.Recognition.SpeechRecognizer>物件，以及相關聯的相關資訊的一些<xref:System.Speech.Recognition.RecognitionResult>。  
  
```csharp  
  
// Handle the SpeechRecognized event.   
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
  Console.WriteLine("Grammar({0}), {1}: {2}",  
    e.Result.Grammar.Name, e.Result.Audio.Duration, e.Result.Text);  
  
  // Display the semantic values in the recognition result.  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine(" {0} key: {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  
    Console.WriteLine(" {0,-10} {1,-10} {2,-10} {3} ({4})",  
      word.Text, word.LexicalForm, word.Pronunciation,  
      audio.Duration, word.DisplayAttributes);  
  }  
  
  // Display the recognition alternates for the result.  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine(" alt({0}) {1}", phrase.Confidence, phrase.Text);  
  }  
}  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
    <altmember cref="T:System.Speech.Recognition.RecognizedPhrase" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected" />
    <altmember cref="E:System.Speech.Recognition.Grammar.SpeechRecognized" />
  </Docs>
  <Members>
    <Member MemberName="Alternates">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt; Alternates { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Recognition.RecognizedPhrase&gt; Alternates" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognitionResult.Alternates" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Alternates As ReadOnlyCollection(Of RecognizedPhrase)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedPhrase ^&gt; ^ Alternates { System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::RecognizedPhrase ^&gt; ^ get(); };" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.RecognizedPhrase&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>取得用於語音辨識器輸入可能的符合項目集合。</summary>
        <value>辨識替代方法的唯讀集合。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 辨識<xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>的值來排序其<xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>屬性。 給定詞彙的信賴值表示片語比對輸入的機率。 具有高信心值的片語是最有可能符合輸入的片語。  
  
 每個<xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>應該評估值，而不參考的其他信賴值及個別<xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>。 屬性的<xref:System.Speech.Recognition.RecognitionResult>繼承自<xref:System.Speech.Recognition.RecognizedPhrase>提供最高信心分數片語的詳細的資訊。  
  
 其中一個使用<xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>集合是自動化的錯誤修正。 例如，在設計目錄對話方塊時，應用程式內容可以提示使用者檢查如果應用程式有正確的資訊從辨識的事件，像是 「 你說 'Anna'？ 」如果使用者可指定"no"，則應用程式無法查詢使用者有夠高而任何替代項目<xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>分數。  
  
 如需 語音辨識和辨識替代項目使用的詳細資訊，請參閱[語音辨識](http://msdn.microsoft.com/library/6a7dc524-07fc-4862-8d48-8c10dc64b919)和[使用語音辨識事件](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)。  
  
   
  
## Examples  
 下列範例示範的處理常式`SpeechRecognized`事件，以及相關聯的相關資訊的一些<xref:System.Speech.Recognition.RecognitionResult>。  
  
```csharp  
  
// Handle the SpeechRecognized event.   
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
  Console.WriteLine("Grammar({0}), {1}: {2}",  
    e.Result.Grammar.Name, e.Result.Audio.Duration, e.Result.Text);  
  
  // Display the semantic values in the recognition result.  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine(" {0} key: {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  
    Console.WriteLine(" {0,-10} {1,-10} {2,-10} {3} ({4})",  
      word.Text, word.LexicalForm, word.Pronunciation,  
      audio.Duration, word.DisplayAttributes);  
  }  
  
  // Display the recognition alternates for the result.  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine(" alt({0}) {1}", phrase.Confidence, phrase.Text);  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
        <altmember cref="T:System.Speech.Recognition.RecognizedPhrase" />
      </Docs>
    </Member>
    <Member MemberName="Audio">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizedAudio Audio { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.RecognizedAudio Audio" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognitionResult.Audio" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Audio As RecognizedAudio" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::RecognizedAudio ^ Audio { System::Speech::Recognition::RecognizedAudio ^ get(); };" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizedAudio</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>取得與便是結果相關聯的音訊。</summary>
        <value>與辨識結果相關聯的音訊，如果辨識器是透過呼叫 <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> 或 <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 執行個體的 <see langword="null" /> 或 <see langword="EmulateRecognize" /> 方法來產生結果則為 <see langword="EmulateRecognizeAsync" />。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 若要取得一段特定的辨識結果中的文字範圍相關聯的音訊，請使用<xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A>方法。  
  
   
  
## Examples  
 下列範例示範的處理常式**SpeechRecognized**事件，以及相關聯的相關資訊的一些<xref:System.Speech.Recognition.RecognitionResult>。  
  
```csharp  
  
// Handle the SpeechRecognized event.   
void SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  // Add event handler code here.  
  
  // The following code illustrates some of the information available  
  // in the recognition result.  
      Console.WriteLine("Grammar({0}): {1}", e.Result.Grammar.Name, e.Result.Text);  
      Console.WriteLine("Audio for result:");  
      Console.WriteLine("  Start time: "+ e.Result.Audio.StartTime);  
      Console.WriteLine("  Duration: " + e.Result.Audio.Duration);  
      Console.WriteLine("  Format: " + e.Result.Audio.Format.EncodingFormat);  
  
  // Display the semantic values in the recognition result.  
  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  
  {  
    Console.WriteLine(" {0} key: {1}",  
      child.Key, child.Value.Value ?? "null");  
  }  
  Console.WriteLine();  
  
  // Display information about the words in the recognition result.  
  foreach (RecognizedWordUnit word in e.Result.Words)  
  {  
    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  
    Console.WriteLine(" {0,-10} {1,-10} {2,-10} {3} ({4})",  
      word.Text, word.LexicalForm, word.Pronunciation,  
      audio.Duration, word.DisplayAttributes);  
  }  
  
  // Display the recognition alternates for the result.  
  foreach (RecognizedPhrase phrase in e.Result.Alternates)  
  {  
    Console.WriteLine(" alt({0}) {1}", phrase.Confidence, phrase.Text);  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
        <altmember cref="T:System.Speech.Recognition.RecognizedPhrase" />
        <altmember cref="M:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)" />
      </Docs>
    </Member>
    <Member MemberName="GetAudioForWordRange">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizedAudio GetAudioForWordRange (System.Speech.Recognition.RecognizedWordUnit firstWord, System.Speech.Recognition.RecognizedWordUnit lastWord);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognizedAudio GetAudioForWordRange(class System.Speech.Recognition.RecognizedWordUnit firstWord, class System.Speech.Recognition.RecognizedWordUnit lastWord) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)" />
      <MemberSignature Language="VB.NET" Value="Public Function GetAudioForWordRange (firstWord As RecognizedWordUnit, lastWord As RecognizedWordUnit) As RecognizedAudio" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognizedAudio ^ GetAudioForWordRange(System::Speech::Recognition::RecognizedWordUnit ^ firstWord, System::Speech::Recognition::RecognizedWordUnit ^ lastWord);" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizedAudio</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="firstWord" Type="System.Speech.Recognition.RecognizedWordUnit" />
        <Parameter Name="lastWord" Type="System.Speech.Recognition.RecognizedWordUnit" />
      </Parameters>
      <Docs>
        <param name="firstWord">範圍內的第一個字。</param>
        <param name="lastWord">範圍內的最後一字。</param>
        <summary>取得辨識結果中與特定文字範圍相關聯的音訊區段。</summary>
        <returns>與文字範圍相關聯的音訊區段。</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 若要取得完整的辨識結果相關聯的音訊，請使用<xref:System.Speech.Recognition.RecognitionResult.Audio%2A>屬性。  
  
   
  
## Examples  
 下列範例會建立接受名稱輸入文法並附加至它的處理常式`SpeechRecognized`事件。 文法會使用該片語的 name 元素萬用字元。 事件處理常式會建立並播放問候語提示字元使用萬用字元音效。  
  
```csharp  
  
private Grammar CreateNameInputGrammar()  
{  
  GrammarBuilder wildcardBuilder = new GrammarBuilder();  
  wildcardBuilder.AppendWildcard();  
  SemanticResultKey nameKey =  
    new SemanticResultKey("Name", wildcardBuilder);  
  
  GrammarBuilder nameBuilder =  
    new GrammarBuilder("My name is");  
  nameBuilder.Append(nameKey);  
  
  Grammar nameGrammar = new Grammar(nameBuilder);  
  nameGrammar.Name = "Name input";  
  
  nameGrammar.SpeechRecognized +=  
    new EventHandler<SpeechRecognizedEventArgs>(  
      NameInputHandler);  
  
  return nameGrammar;  
}  
  
// Handle the SpeechRecognized event for the name grammar.  
private void NameInputHandler(object sender, SpeechRecognizedEventArgs e)  
{  
  if (e.Result == null) return;  
  
  RecognitionResult result = e.Result;  
  SemanticValue semantics = e.Result.Semantics;  
  
  if (semantics.ContainsKey("Name"))  
  {  
    RecognizedAudio nameAudio =  
      result.GetAudioForWordRange(  
        result.Words[3], result.Words[result.Words.Count - 1]);  
  
    // Save the audio. Create a directory and file as necessary.  
    FileInfo fi = new FileInfo(@"C:\temp\temp.wav");  
    if (!fi.Directory.Exists)  
    {  
      fi.Directory.Create();  
    }  
    FileStream stream = new FileStream(fi.FullName, FileMode.Create);  
    nameAudio.WriteToWaveStream(stream);  
    stream.Close();  
  
    // Greet the person using the saved audio.  
    SpeechSynthesizer synthesizer = new SpeechSynthesizer();  
    PromptBuilder builder = new PromptBuilder();  
    builder.AppendText("Hello");  
    builder.AppendAudio(fi.FullName);  
    synthesizer.Speak(builder);  
  }  
}  
```  
  
 ]]></format>
        </remarks>
        <exception cref="T:System.NullReferenceException">辨識器已透過呼叫 <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 或 <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> 物件的 <see langword="EmulateRecognize" /> 或 <see langword="EmulateRecognizeAsync" /> 方法產生結果。</exception>
        <altmember cref="T:System.Speech.Recognition.RecognitionEventArgs" />
        <altmember cref="T:System.Speech.Recognition.RecognizedPhrase" />
        <altmember cref="T:System.Speech.Recognition.RecognizedWordUnit" />
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Audio" />
        <altmember cref="P:System.Speech.Recognition.RecognizedPhrase.Words" />
      </Docs>
    </Member>
    <Member MemberName="System.Runtime.Serialization.ISerializable.GetObjectData">
      <MemberSignature Language="C#" Value="void ISerializable.GetObjectData (System.Runtime.Serialization.SerializationInfo info, System.Runtime.Serialization.StreamingContext context);" />
      <MemberSignature Language="ILAsm" Value=".method hidebysig newslot virtual instance void System.Runtime.Serialization.ISerializable.GetObjectData(class System.Runtime.Serialization.SerializationInfo info, valuetype System.Runtime.Serialization.StreamingContext context) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)" />
      <MemberSignature Language="VB.NET" Value="Sub GetObjectData (info As SerializationInfo, context As StreamingContext) Implements ISerializable.GetObjectData" />
      <MemberSignature Language="C++ CLI" Value=" virtual void System.Runtime.Serialization.ISerializable.GetObjectData(System::Runtime::Serialization::SerializationInfo ^ info, System::Runtime::Serialization::StreamingContext context) = System::Runtime::Serialization::ISerializable::GetObjectData;" />
      <MemberType>Method</MemberType>
      <Implements>
        <InterfaceMember>M:System.Runtime.Serialization.ISerializable.GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)</InterfaceMember>
      </Implements>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="info" Type="System.Runtime.Serialization.SerializationInfo" />
        <Parameter Name="context" Type="System.Runtime.Serialization.StreamingContext" />
      </Parameters>
      <Docs>
        <param name="info">要填入資料的物件。</param>
        <param name="context">序列化的目的端。</param>
        <summary>將序列化目標物件所需的資料填入 <see cref="T:System.Runtime.Serialization.SerializationInfo" /> 執行個體。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 這個成員是明確介面成員實作， 只有在 <xref:System.Speech.Recognition.RecognitionResult> 執行個體轉換成 <xref:System.Runtime.Serialization.ISerializable> 介面時，才能使用這個成員。  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Runtime.Serialization.ISerializable" />
        <altmember cref="T:System.Runtime.Serialization.SerializationInfo" />
        <altmember cref="T:System.Runtime.Serialization.StreamingContext" />
      </Docs>
    </Member>
  </Members>
</Type>