<Type Name="SpeechRecognizer" FullName="System.Speech.Recognition.SpeechRecognizer">
  <Metadata><Meta Name="ms.openlocfilehash" Value="7f19e98d364cd16bffbf58714877f22e676a4052" /><Meta Name="ms.sourcegitcommit" Value="0e1f030650a307c745ee84ed547ef858acaea587" /><Meta Name="ms.translationtype" Value="HT" /><Meta Name="ms.contentlocale" Value="zh-TW" /><Meta Name="ms.lasthandoff" Value="11/29/2018" /><Meta Name="ms.locfileid" Value="52596019" /></Metadata><TypeSignature Language="C#" Value="public class SpeechRecognizer : IDisposable" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit SpeechRecognizer extends System.Object implements class System.IDisposable" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.SpeechRecognizer" />
  <TypeSignature Language="VB.NET" Value="Public Class SpeechRecognizer&#xA;Implements IDisposable" />
  <TypeSignature Language="C++ CLI" Value="public ref class SpeechRecognizer : IDisposable" />
  <TypeSignature Language="F#" Value="type SpeechRecognizer = class&#xA;    interface IDisposable" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces>
    <Interface>
      <InterfaceName>System.IDisposable</InterfaceName>
    </Interface>
  </Interfaces>
  <Docs>
    <summary>為 Windows 桌面上共用的語音辨識服務提供存取。</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 應用程式會使用共用辨識器，來存取 Windows 語音辨識。 使用<xref:System.Speech.Recognition.SpeechRecognizer>物件新增至 Windows 語音使用者體驗。  
  
 這個類別提供控制語音辨識程序的各個層面：  
  
-   若要管理的語音辨識文法，請使用<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A>，和<xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A>。  
  
-   若要取得資訊目前語音辨識作業，請訂閱<xref:System.Speech.Recognition.SpeechRecognizer>的<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>， <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>， <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>，和<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件。  
  
-   若要檢視或修改的辨識器傳回的替代結果數目，請使用<xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A>屬性。 辨識器傳回在辨識結果<xref:System.Speech.Recognition.RecognitionResult>物件。  
  
-   若要存取，或監視共用辨識器的狀態，請使用<xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>，以及<xref:System.Speech.Recognition.SpeechRecognizer.State%2A>屬性和<xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated>， <xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred>， <xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged>，和<xref:System.Speech.Recognition.SpeechRecognizer.StateChanged>事件。  
  
-   若要變更同步至辨識器，使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>方法。 共用辨識器會使用一個以上的執行緒來執行工作。  
  
-   若要模擬對共用辨識器的輸入，使用<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>和<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>方法。  
  
 Windows 語音辨識的組態使用由管理**語音內容** 對話方塊中的**控制台**。 此介面用來選取預設桌面的語音辨識引擎和語言、 音訊輸入的裝置及語音辨識的睡眠行為。 如果 Windows 語音辨識的組態變更當應用程式執行時，（比方說，如果已停用 語音辨識，或輸入的語言變更），變更會影響所有<xref:System.Speech.Recognition.SpeechRecognizer>物件。  
  
 若要建立獨立於 Windows 語音辨識的內含式語音辨識器，請使用<xref:System.Speech.Recognition.SpeechRecognitionEngine>類別。  
  
> [!NOTE]
>  請務必呼叫<xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A>發行您的語音辨識器的最後一個參考之前。 否則，它所使用的資源將不會釋放之前，記憶體回收行程呼叫辨識器物件的`Finalize`方法。  
  
   
  
## Examples  
 下列範例是主控台應用程式載入語音辨識文法，並示範非同步模擬的輸入、 相關聯的辨識結果，以及語音辨識器所引發的相關聯的事件的一部分。  如果未執行 Windows 語音辨識，然後啟動此應用程式將也會啟動 Windows 語音辨識。 如果 Windows 語音辨識處於**睡眠**狀態，然後<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>一定會傳回 null。  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.   
        // This matches the grammar and generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.  
        // This does not match the grammar or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the SpeechRecognizeCompleted event.  
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      // Indicate the asynchronous operation is complete.  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
    <altmember cref="T:System.Speech.Recognition.Grammar" />
    <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.#ctor" />
      <MemberSignature Language="VB.NET" Value="Public Sub New ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; SpeechRecognizer();" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters />
      <Docs>
        <summary>初始化 <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 類別的新執行個體。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 每個<xref:System.Speech.Recognition.SpeechRecognizer>物件會維護一組個別的語音辨識文法。  
  
   
  
## Examples  
 下列範例是主控台應用程式載入語音辨識文法，並示範非同步模擬的輸入、 相關聯的辨識結果，以及語音辨識器所引發的相關聯的事件的一部分。 如果未執行 Windows 語音辨識，然後啟動此應用程式將也會啟動 Windows 語音辨識。 如果 Windows 語音辨識處於**睡眠**狀態，然後<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>一定會傳回 null。  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.   
        // This matches the grammar and generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.  
        // This does not match the grammar or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the SpeechRecognizeCompleted event.  
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      // Indicate the asynchronous operation is complete.  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="T:System.Speech.Recognition.Grammar" />
      </Docs>
    </Member>
    <Member MemberName="AudioFormat">
      <MemberSignature Language="C#" Value="public System.Speech.AudioFormat.SpeechAudioFormatInfo AudioFormat { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.AudioFormat.SpeechAudioFormatInfo AudioFormat" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioFormat" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioFormat As SpeechAudioFormatInfo" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::AudioFormat::SpeechAudioFormatInfo ^ AudioFormat { System::Speech::AudioFormat::SpeechAudioFormatInfo ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioFormat : System.Speech.AudioFormat.SpeechAudioFormatInfo" Usage="System.Speech.Recognition.SpeechRecognizer.AudioFormat" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.AudioFormat.SpeechAudioFormatInfo</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>取得語音辨識器所接收的音訊格式。</summary>
        <value>語音格式，如果未設定辨識器的輸入則為 <see langword="null" />。</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AudioLevel">
      <MemberSignature Language="C#" Value="public int AudioLevel { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 AudioLevel" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioLevel" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioLevel As Integer" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property int AudioLevel { int get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioLevel : int" Usage="System.Speech.Recognition.SpeechRecognizer.AudioLevel" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>取得語音辨識器所接收的音訊層級。</summary>
        <value>語音辨識器的輸入音量，大小從 0 到 100。</value>
        <remarks>To be added.</remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated" />
      </Docs>
    </Member>
    <Member MemberName="AudioLevelUpdated">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; AudioLevelUpdated;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; AudioLevelUpdated" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event AudioLevelUpdated As EventHandler(Of AudioLevelUpdatedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::AudioLevelUpdatedEventArgs ^&gt; ^ AudioLevelUpdated;" />
      <MemberSignature Language="F#" Value="member this.AudioLevelUpdated : EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; " Usage="member this.AudioLevelUpdated : System.EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>當共用辨識器報告其音訊輸入層級時發生。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 辨識器會引發這個事件每秒數次。 用來引發事件的頻率取決於應用程式執行所在的電腦。  
  
 若要取得的音訊層級事件時，請使用<xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A>相關聯的屬性<xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs>。 若要取得目前的辨識器的輸入音訊層級，使用辨識器<xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>屬性。  
  
 當您建立的委派`AudioLevelUpdated`事件，識別即將處理此事件的方法。 若要使事件與您的事件處理常式產生關聯，請將委派的執行個體 (Instance) 加入至事件。 除非您移除委派，否則每當事件發生時就會呼叫事件處理常式。 如需有關事件處理常式委派的詳細資訊，請參閱[事件與委派](https://go.microsoft.com/fwlink/?LinkId=162418)。  
  
   
  
## Examples  
 下列範例會加入處理常式`AudioLevelUpdated`事件，以<xref:System.Speech.Recognition.SpeechRecognizer>物件。 處理常式會輸出新的音訊層級寫入主控台。  
  
```csharp  
private SpeechRecognizer recognizer;  
  
// Initialize the SpeechRecognizer object.   
private void Initialize()  
{  
  recognizer = new SpeechRecognizer();  
  
  // Add an event handler for the AudioLevelUpdated event.  
  recognizer.AudioLevelUpdated +=   
    new EventHandler<AudioLevelUpdatedEventArgs>(recognizer_AudioLevelUpdated);  
  
  // Add other initialization code here.  
  
}  
  
// Write the audio level to the console when the AudioLevelUpdated event is raised.  
void recognizer_AudioLevelUpdated(object sender, AudioLevelUpdatedEventArgs e)  
{  
  Console.WriteLine("The audio level is now: {0}.", e.AudioLevel);  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.AudioLevelUpdatedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioLevel" />
      </Docs>
    </Member>
    <Member MemberName="AudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan AudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan AudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioPosition As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan AudioPosition { TimeSpan get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioPosition : TimeSpan" Usage="System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>取得提供語音辨識器輸入的裝置正在產生的音訊資料流中目前的位置。</summary>
        <value>語音辨識器自其中接收到輸入之音訊輸入資料流中的目前位置。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 共用辨識器接收輸入，而桌面的語音辨識 正在執行。  
  
 `AudioPosition`屬性會參考其產生的音訊資料流中的輸入的裝置的位置。 相較之下，<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>屬性參考中處理音訊輸入的辨識器的位置。 這些位置可能會不同。  比方說，如果辨識器已收到輸入其已不但產生的值就辨識結果<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>屬性是值小於<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>屬性。  
  
   
  
## Examples  
 在下列範例中，共用的語音辨識器會使用聽寫文法，若要比對語音輸入。 處理常式<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>事件會寫入主控台<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>，和<xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>當語音辨識器偵測到在其輸入的語音。  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
      // Add handlers for events.  
      recognizer.LoadGrammarCompleted +=   
        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
      recognizer.SpeechRecognized +=   
        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
      recognizer.StateChanged +=   
        new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
      recognizer.SpeechDetected +=   
        new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  
  
      // Create a dictation grammar.  
      Grammar dictation = new DictationGrammar();  
      dictation.Name = "Dictation";  
  
      // Load the grammar object to the recognizer.  
      recognizer.LoadGrammarAsync(dictation);  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Gather information about detected speech and write it to the console.  
    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  
    {  
      Console.WriteLine();  
      Console.WriteLine("Speech detected:");  
      Console.WriteLine("  Audio level: " + recognizer.AudioLevel);  
      Console.WriteLine("  Audio position: " + recognizer.AudioPosition);  
      Console.WriteLine("  Recognizer audio position: " + recognizer.RecognizerAudioPosition);  
    }  
  
    // Write the text of the recognition result to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {   
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
  
      // Add event handler code here.  
    }  
  
    // Write the name of the loaded grammar to the console.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Put the shared speech recognizer into "listening" mode.  
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="AudioSignalProblemOccurred">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; AudioSignalProblemOccurred;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; AudioSignalProblemOccurred" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event AudioSignalProblemOccurred As EventHandler(Of AudioSignalProblemOccurredEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::AudioSignalProblemOccurredEventArgs ^&gt; ^ AudioSignalProblemOccurred;" />
      <MemberSignature Language="F#" Value="member this.AudioSignalProblemOccurred : EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; " Usage="member this.AudioSignalProblemOccurred : System.EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>在辨識器遇到音訊訊號的問題時發生。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 若要取得發生的問題，請使用<xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A>相關聯的屬性<xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>。  
  
 當您建立的委派`AudioSignalProblemOccurred`事件，識別即將處理此事件的方法。 若要使事件與您的事件處理常式產生關聯，請將委派的執行個體 (Instance) 加入至事件。 除非您移除委派，否則每當事件發生時就會呼叫事件處理常式。 如需有關事件處理常式委派的詳細資訊，請參閱[事件與委派](https://go.microsoft.com/fwlink/?LinkId=162418)。  
  
   
  
## Examples  
 下列範例會定義需收集資訊的事件處理常式`AudioSignalProblemOccurred`事件。  
  
```  
private SpeechRecognizer recognizer;  
  
// Initialize the speech recognition engine.  
private void Initialize()  
{  
  recognizer = new SpeechRecognizer();  
  
  // Add a handler for the AudioSignalProblemOccurred event.  
  recognizer.AudioSignalProblemOccurred +=   
    new EventHandler<AudioSignalProblemOccurredEventArgs>(  
      recognizer_AudioSignalProblemOccurred);  
}  
  
// Gather information when the AudioSignalProblemOccurred event is raised.  
void recognizer_AudioSignalProblemOccurred(object sender, AudioSignalProblemOccurredEventArgs e)  
{  
  StringBuilder details = new StringBuilder();  
  
  details.AppendLine("Audio signal problem information:");  
  details.AppendFormat(  
    " Audio level:               {0}" + Environment.NewLine +  
    " Audio position:            {1}" + Environment.NewLine +  
    " Audio signal problem:      {2}" + Environment.NewLine +  
    " Recognition engine audio position: {3}" + Environment.NewLine,  
    e.AudioLevel, e.AudioPosition,  e.AudioSignalProblem,  
    e.recoEngineAudioPosition);  
  
  // Insert additional event handler code here.  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.AudioSignalProblem" />
        <altmember cref="T:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs" />
      </Docs>
    </Member>
    <Member MemberName="AudioState">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.AudioState AudioState { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Speech.Recognition.AudioState AudioState" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioState" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioState As AudioState" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::AudioState AudioState { System::Speech::Recognition::AudioState get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioState : System.Speech.Recognition.AudioState" Usage="System.Speech.Recognition.SpeechRecognizer.AudioState" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.AudioState</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>取得語音辨識器所接收的音訊狀態。</summary>
        <value>語音辨識器之音訊輸入的狀態。</value>
        <remarks>To be added.</remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged" />
      </Docs>
    </Member>
    <Member MemberName="AudioStateChanged">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt; AudioStateChanged;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.AudioStateChangedEventArgs&gt; AudioStateChanged" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event AudioStateChanged As EventHandler(Of AudioStateChangedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::AudioStateChangedEventArgs ^&gt; ^ AudioStateChanged;" />
      <MemberSignature Language="F#" Value="member this.AudioStateChanged : EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt; " Usage="member this.AudioStateChanged : System.EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>在辨識器所接收的音訊變更狀態時發生。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 若要取得的音訊狀態事件時，請使用<xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A>相關聯的屬性<xref:System.Speech.Recognition.AudioStateChangedEventArgs>。 取得辨識器的輸入音訊的目前狀態，請使用辨識器<xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A>屬性。 如需音訊狀態的詳細資訊，請參閱<xref:System.Speech.Recognition.AudioState>列舉型別。  
  
 當您建立的委派`AudioStateChanged`事件，識別即將處理此事件的方法。 若要使事件與您的事件處理常式產生關聯，請將委派的執行個體 (Instance) 加入至事件。 除非您移除委派，否則每當事件發生時就會呼叫事件處理常式。 如需有關事件處理常式委派的詳細資訊，請參閱[事件與委派](https://go.microsoft.com/fwlink/?LinkId=162418)。  
  
   
  
## Examples  
 下列範例使用的處理常式`AudioStateChanged`要寫入辨識器事件的新<xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A>主控台每次使用的成員變更<xref:System.Speech.Recognition.AudioState>列舉型別。  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
        // Create and load a grammar.  
        Grammar dictation = new DictationGrammar();  
        dictation.Name = "Dictation Grammar";  
        recognizer.LoadGrammar(dictation);  
  
        // Attach event handlers.  
        recognizer.AudioStateChanged +=  
          new EventHandler<AudioStateChangedEventArgs>(recognizer_AudioStateChanged);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.StateChanged +=  
          new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
  
    // Handle the AudioStateChanged event.  
    static void recognizer_AudioStateChanged(object sender, AudioStateChangedEventArgs e)  
    {  
      Console.WriteLine("The new audio state is: " + e.AudioState);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null && e.Result.Text != null)  
      {  
        Console.WriteLine();  
        Console.WriteLine("  Recognized text =  {0}", e.Result.Text);  
        Console.WriteLine();  
      }  
      else  
      {  
        Console.WriteLine("  Recognized text not available.");  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Done.");  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Put the recognizer into Listening mode.  
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        Console.WriteLine();  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.AudioState" />
        <altmember cref="T:System.Speech.Recognition.AudioStateChangedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioState" />
      </Docs>
    </Member>
    <MemberGroup MemberName="Dispose">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>處置 <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 物件。</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="Dispose">
      <MemberSignature Language="C#" Value="public void Dispose ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance void Dispose() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.Dispose" />
      <MemberSignature Language="VB.NET" Value="Public Sub Dispose ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; virtual void Dispose();" />
      <MemberSignature Language="F#" Value="abstract member Dispose : unit -&gt; unit&#xA;override this.Dispose : unit -&gt; unit" Usage="speechRecognizer.Dispose " />
      <MemberType>Method</MemberType>
      <Implements>
        <InterfaceMember>M:System.IDisposable.Dispose</InterfaceMember>
      </Implements>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>處置 <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 物件。</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Dispose">
      <MemberSignature Language="C#" Value="protected virtual void Dispose (bool disposing);" />
      <MemberSignature Language="ILAsm" Value=".method familyhidebysig newslot virtual instance void Dispose(bool disposing) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)" />
      <MemberSignature Language="VB.NET" Value="Protected Overridable Sub Dispose (disposing As Boolean)" />
      <MemberSignature Language="C++ CLI" Value="protected:&#xA; virtual void Dispose(bool disposing);" />
      <MemberSignature Language="F#" Value="abstract member Dispose : bool -&gt; unit&#xA;override this.Dispose : bool -&gt; unit" Usage="speechRecognizer.Dispose disposing" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="disposing" Type="System.Boolean" />
      </Parameters>
      <Docs>
        <param name="disposing"><see langword="true" /> 表示釋放 Managed 和 Unmanaged 資源，<see langword="false" /> 則表示只釋放 Unmanaged 資源。</param>
        <summary>處置 <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 物件，並釋放工作階段期間所使用的資源。</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="EmulateRecognize">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>在同步語音辨識中使用文字而不使用音訊，模擬對共用語音辨識器的輸入。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 這些方法會略過系統音訊輸入。 當您正在測試或偵錯的應用程式或文法，這可以是很有幫助。  
  
> [!NOTE]
>  如果 Windows 語音辨識處於**睡眠**狀態，則這些方法會傳回`null`。  
  
 共用辨識器會引發<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>， <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>， <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>，和<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件彷彿未模擬辨識作業。 辨識器會忽略新行和額外的空白字元和標點符號視為常值的輸入。  
  
> [!NOTE]
>  <xref:System.Speech.Recognition.RecognitionResult>共用辨識器，以模擬輸入的回應所產生的物件具有值`null`針對其<xref:System.Speech.Recognition.RecognitionResult.Audio%2A>屬性。  
  
 若要模擬非同步辨識，使用<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>方法。  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="EmulateRecognize">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognitionResult EmulateRecognize(string inputText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Function EmulateRecognize (inputText As String) As RecognitionResult" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognitionResult ^ EmulateRecognize(System::String ^ inputText);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognize : string -&gt; System.Speech.Recognition.RecognitionResult" Usage="speechRecognizer.EmulateRecognize inputText" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="inputText">辨識作業的輸出。</param>
        <summary>在共用的語音辨識器上模擬片語輸入，針對同步的語音辨識使用文字而不使用音訊。</summary>
        <returns>辨識作業的辨識結果，如果作業不成功或 Windows 語音辨識處於 [睡眠] 狀態則為 <see langword="null" />。</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Vista 和 Windows 7 隨附的辨識器會忽略大小寫，並將文法規則套用至輸入的片語時，字元寬度。 如需這種類型的比較的詳細資訊，請參閱<xref:System.Globalization.CompareOptions>列舉值<xref:System.Globalization.CompareOptions.OrdinalIgnoreCase>和<xref:System.Globalization.CompareOptions.IgnoreWidth>。 辨識器也會忽略新行，以及額外的空白字元和標點符號視為常值的輸入。  
  
   
  
## Examples  
 下列範例會載入範例文法共用辨識器，並模擬辨識器輸入。 如果未執行 Windows 語音辨識，然後啟動此應用程式將也會啟動 Windows 語音辨識。 如果 Windows 語音辨識處於**睡眠**狀態，然後<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>一定會傳回 null。  
  
```csharp  
  
using System;  
using System.Speech.Recognition;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
  
    static void Main(string[] args)  
    {  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
  
        recognizer.LoadGrammar(testGrammar);  
  
        RecognitionResult result;  
  
        // This EmulateRecognize call matches the grammar and returns a  
        // recognition result.  
        result = recognizer.EmulateRecognize("testing testing");  
        OutputResult(result);  
  
        // This EmulateRecognize call does not match the grammar and   
        // returns null.  
        result = recognizer.EmulateRecognize("testing one two three");  
        OutputResult(result);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Output information about a recognition result to the console.  
    private static void OutputResult(RecognitionResult result)  
    {  
      if (result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognize">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult EmulateRecognize (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognitionResult EmulateRecognize(class System.Speech.Recognition.RecognizedWordUnit[] wordUnits, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognitionResult ^ EmulateRecognize(cli::array &lt;System::Speech::Recognition::RecognizedWordUnit ^&gt; ^ wordUnits, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognize : System.Speech.Recognition.RecognizedWordUnit[] * System.Globalization.CompareOptions -&gt; System.Speech.Recognition.RecognitionResult" Usage="speechRecognizer.EmulateRecognize (wordUnits, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="wordUnits" Type="System.Speech.Recognition.RecognizedWordUnit[]" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="wordUnits">文字單位陣列，包含辨識作業的輸入。</param>
        <param name="compareOptions">列舉值的位元組合，描述要用於模擬辨識作業的比較類型。</param>
        <summary>在共用的語音辨識器上模擬特定單字輸入，針對同步的語音辨識使用文字而不使用音訊，並指定辨識器如何處理單字間的 Unicode 比較以及已載入的語音辨識文法。</summary>
        <returns>辨識作業的辨識結果，如果作業不成功或 Windows 語音辨識處於 [睡眠] 狀態則為 <see langword="null" />。</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 這個方法會建立<xref:System.Speech.Recognition.RecognitionResult>物件使用所提供的資訊`wordUnits`參數。  
  
 辨識器使用`compareOptions`當它適用於文法規則進行剖析的輸入片語。 Vista 和 Windows 7 隨附的辨識器忽略大小寫，如果<xref:System.Globalization.CompareOptions.OrdinalIgnoreCase>或<xref:System.Globalization.CompareOptions.IgnoreCase>值。 辨識器一律忽略字元寬度，並永遠不會忽略假名類型。 辨識器也會忽略新行，以及額外的空白字元和標點符號視為常值的輸入。 如需有關字元寬度] 和 [假名類型的詳細資訊，請參閱<xref:System.Globalization.CompareOptions>列舉型別。  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognize">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognitionResult EmulateRecognize(string inputText, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognitionResult ^ EmulateRecognize(System::String ^ inputText, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognize : string * System.Globalization.CompareOptions -&gt; System.Speech.Recognition.RecognitionResult" Usage="speechRecognizer.EmulateRecognize (inputText, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="inputText">辨識作業的輸入片語。</param>
        <param name="compareOptions">列舉值的位元組合，描述要用於模擬辨識作業的比較類型。</param>
        <summary>在共用的語音辨識器上模擬片語輸入，針對同步的語音辨識使用文字而不使用音訊，並指定辨識器如何處理片語間的 Unicode 比較以及已載入的語音辨識文法。</summary>
        <returns>辨識作業的辨識結果，如果作業不成功或 Windows 語音辨識處於 [睡眠] 狀態則為 <see langword="null" />。</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 辨識器使用`compareOptions`當它適用於文法規則進行剖析的輸入片語。 Vista 和 Windows 7 隨附的辨識器忽略大小寫，如果<xref:System.Globalization.CompareOptions.OrdinalIgnoreCase>或<xref:System.Globalization.CompareOptions.IgnoreCase>值。 辨識器一律忽略字元寬度，並永遠不會忽略假名類型。 辨識器也會忽略新行，以及額外的空白字元和標點符號視為常值的輸入。 如需有關字元寬度] 和 [假名類型的詳細資訊，請參閱<xref:System.Globalization.CompareOptions>列舉型別。  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <MemberGroup MemberName="EmulateRecognizeAsync">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>在非同步語音辨識中使用文字而不使用音訊，模擬對共用語音辨識器的輸入。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 這些方法會略過系統音訊輸入。 當您正在測試或偵錯的應用程式或文法，這可以是很有幫助。  
  
 共用辨識器會引發<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>， <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>， <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>，和<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件彷彿未模擬辨識作業。 當辨識器完成非同步辨識作業時，會引發<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted>事件。 辨識器會忽略新行和額外的空白字元和標點符號視為常值的輸入。  
  
> [!NOTE]
>  如果 Windows 語音辨識處於**睡眠**狀態，則共用辨識器不會處理輸入，並不會引發<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>和相關的事件，但仍會引發<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted>事件。  
  
> [!NOTE]
>  <xref:System.Speech.Recognition.RecognitionResult>共用辨識器，以模擬輸入的回應所產生的物件具有值`null`針對其<xref:System.Speech.Recognition.RecognitionResult.Audio%2A>屬性。  
  
 若要模擬同步辨識，使用<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>方法。  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="EmulateRecognizeAsync">
      <MemberSignature Language="C#" Value="public void EmulateRecognizeAsync (string inputText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EmulateRecognizeAsync(string inputText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub EmulateRecognizeAsync (inputText As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EmulateRecognizeAsync(System::String ^ inputText);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeAsync : string -&gt; unit" Usage="speechRecognizer.EmulateRecognizeAsync inputText" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="inputText">辨識作業的輸出。</param>
        <summary>在共用的語音辨識器上模擬片語輸入，針對非同步的語音辨識使用文字而不使用音訊。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Vista 和 Windows 7 隨附的辨識器會忽略大小寫，並將文法規則套用至輸入的片語時，字元寬度。 如需這種類型的比較的詳細資訊，請參閱<xref:System.Globalization.CompareOptions>列舉值<xref:System.Globalization.CompareOptions.OrdinalIgnoreCase>和<xref:System.Globalization.CompareOptions.IgnoreWidth>。 辨識器也會忽略新行，以及額外的空白字元和標點符號視為常值的輸入。  
  
   
  
## Examples  
 下列範例是主控台應用程式載入語音辨識文法，並示範非同步模擬的輸入、 相關聯的辨識結果，以及語音辨識器所引發的相關聯的事件的一部分。 如果未執行 Windows 語音辨識，然後啟動此應用程式將也會啟動 Windows 語音辨識。 如果 Windows 語音辨識處於**睡眠**狀態，然後<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>一定會傳回 null。  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call does not match the grammar   
        // or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the EmulateRecognizeCompleted event.   
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognizeAsync">
      <MemberSignature Language="C#" Value="public void EmulateRecognizeAsync (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EmulateRecognizeAsync(class System.Speech.Recognition.RecognizedWordUnit[] wordUnits, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EmulateRecognizeAsync(cli::array &lt;System::Speech::Recognition::RecognizedWordUnit ^&gt; ^ wordUnits, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeAsync : System.Speech.Recognition.RecognizedWordUnit[] * System.Globalization.CompareOptions -&gt; unit" Usage="speechRecognizer.EmulateRecognizeAsync (wordUnits, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="wordUnits" Type="System.Speech.Recognition.RecognizedWordUnit[]" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="wordUnits">文字單位陣列，包含辨識作業的輸入。</param>
        <param name="compareOptions">列舉值的位元組合，描述要用於模擬辨識作業的比較類型。</param>
        <summary>在共用的語音辨識器上模擬特定單字輸入，針對非同步的語音辨識使用文字而不使用音訊，並指定辨識器如何處理單字間的 Unicode 比較以及已載入的語音辨識文法。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 這個方法會建立<xref:System.Speech.Recognition.RecognitionResult>物件使用所提供的資訊`wordUnits`參數。  
  
 辨識器使用`compareOptions`當它適用於文法規則進行剖析的輸入片語。 Vista 和 Windows 7 隨附的辨識器忽略大小寫，如果<xref:System.Globalization.CompareOptions.OrdinalIgnoreCase>或<xref:System.Globalization.CompareOptions.IgnoreCase>值。 辨識器一律忽略字元寬度，並永遠不會忽略假名類型。 辨識器也會忽略新行，以及額外的空白字元和標點符號視為常值的輸入。 如需有關字元寬度] 和 [假名類型的詳細資訊，請參閱<xref:System.Globalization.CompareOptions>列舉型別。  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognizeAsync">
      <MemberSignature Language="C#" Value="public void EmulateRecognizeAsync (string inputText, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EmulateRecognizeAsync(string inputText, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EmulateRecognizeAsync(System::String ^ inputText, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeAsync : string * System.Globalization.CompareOptions -&gt; unit" Usage="speechRecognizer.EmulateRecognizeAsync (inputText, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="inputText">辨識作業的輸入片語。</param>
        <param name="compareOptions">列舉值的位元組合，描述要用於模擬辨識作業的比較類型。</param>
        <summary>在共用的語音辨識器上模擬片語輸入，針對非同步的語音辨識使用文字而不使用音訊，並指定辨識器如何處理片語間的 Unicode 比較以及已載入的語音辨識文法。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 辨識器使用`compareOptions`當它適用於文法規則進行剖析的輸入片語。 Vista 和 Windows 7 隨附的辨識器忽略大小寫，如果<xref:System.Globalization.CompareOptions.OrdinalIgnoreCase>或<xref:System.Globalization.CompareOptions.IgnoreCase>值。 辨識器一律忽略字元寬度，並永遠不會忽略假名類型。 辨識器也會忽略新行，以及額外的空白字元和標點符號視為常值的輸入。 如需有關字元寬度] 和 [假名類型的詳細資訊，請參閱<xref:System.Globalization.CompareOptions>列舉型別。  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognizeCompleted">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; EmulateRecognizeCompleted;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; EmulateRecognizeCompleted" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
      <MemberSignature Language="VB.NET" Value="Public Event EmulateRecognizeCompleted As EventHandler(Of EmulateRecognizeCompletedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::EmulateRecognizeCompletedEventArgs ^&gt; ^ EmulateRecognizeCompleted;" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeCompleted : EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; " Usage="member this.EmulateRecognizeCompleted : System.EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>共用辨識器針對模擬輸入完成非同步辨識作業時發生。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 每個<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>方法開始非同步辨識作業。 辨識器引發`EmulateRecognizeCompleted`它結束非同步作業的事件。  
  
 非同步辨識作業可能會引發<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>， <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>， <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>，和<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件。 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted>事件是最後一次該辨識器會針對指定的作業會引發這類事件。  
  
 當您建立的委派`EmulateRecognizeCompleted`事件，識別即將處理此事件的方法。 若要使事件與您的事件處理常式產生關聯，請將委派的執行個體 (Instance) 加入至事件。 除非您移除委派，否則每當事件發生時就會呼叫事件處理常式。 如需有關事件處理常式委派的詳細資訊，請參閱[事件與委派](https://go.microsoft.com/fwlink/?LinkId=162418)。  
  
   
  
## Examples  
 下列範例是主控台應用程式載入語音辨識文法，並示範非同步模擬的輸入、 相關聯的辨識結果，以及語音辨識器所引發的相關聯的事件的一部分。 如果未執行 Windows 語音辨識，然後啟動此應用程式將也會啟動 Windows 語音辨識。 如果 Windows 語音辨識處於**睡眠**模式，然後<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>一定會傳回 null。  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=   
          new EventHandler<SpeechRecognizedEventArgs>(SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=   
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call does not match the grammar  
        // or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the EmulateRecognizeCompleted event.  
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      // Indicate the asynchronous operation is complete.  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="Enabled">
      <MemberSignature Language="C#" Value="public bool Enabled { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance bool Enabled" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.Enabled" />
      <MemberSignature Language="VB.NET" Value="Public Property Enabled As Boolean" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property bool Enabled { bool get(); void set(bool value); };" />
      <MemberSignature Language="F#" Value="member this.Enabled : bool with get, set" Usage="System.Speech.Recognition.SpeechRecognizer.Enabled" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Boolean</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>取得或設定值，這個值表示這個 <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 物件是否準備好可以處理語音。</summary>
        <value>如果這個 <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 物件正在執行語音辨識則為 <see langword="true" />，否則為 <see langword="false" />。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 此屬性的變更不會影響其他執行個體會<xref:System.Speech.Recognition.SpeechRecognizer>類別。  
  
 根據預設，windows 7<xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>屬性是`true`的新具現化執行個體<xref:System.Speech.Recognition.SpeechRecognizer>。 辨識器已停用時，辨識器的語音辨識文法中沒有任何可辨識作業。 設定辨識器<xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>屬性沒有任何影響，在辨識器上的<xref:System.Speech.Recognition.SpeechRecognizer.State%2A>屬性。  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition" />
      </Docs>
    </Member>
    <Member MemberName="Grammars">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.Grammar&gt; Grammars { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Recognition.Grammar&gt; Grammars" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Grammars As ReadOnlyCollection(Of Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::Grammar ^&gt; ^ Grammars { System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::Grammar ^&gt; ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Grammars : System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.Grammar&gt;" Usage="System.Speech.Recognition.SpeechRecognizer.Grammars" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.Grammar&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>取得在這個 <see cref="T:System.Speech.Recognition.Grammar" /> 執行個體中載入之 <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 物件的集合。</summary>
        <value><see cref="T:System.Speech.Recognition.Grammar" />物件的集合，應用程式會將這些物件載入共用的辨識器的目前執行個體中。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 這個屬性不會傳回任何語音辨識文法載入另一個應用程式。  
  
   
  
## Examples  
 下列範例會輸出到主控台以供每個共用的語音辨識器所載入的語音辨識文法的資訊。  
  
```csharp  
  
using System;  
using System.Collections.Generic;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        Grammar sampleGrammar = new Grammar(new GrammarBuilder("sample phrase"));  
        sampleGrammar.Name = "Sample Grammar";  
        recognizer.LoadGrammar(sampleGrammar);  
  
        OutputGrammarList(recognizer);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    private static void OutputGrammarList(SpeechRecognizer recognizer)  
    {  
      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
      if (grammars.Count > 0)  
      {  
        Console.WriteLine("Loaded grammars:");  
        foreach (Grammar g in grammars)  
        {  
          Console.WriteLine("  Grammar: {0}",  
            (g.Name != null) ? g.Name : "<no name>");  
        }  
      }  
      else  
      {  
        Console.WriteLine("No grammars loaded.");  
      }  
    }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
      </Docs>
    </Member>
    <Member MemberName="LoadGrammar">
      <MemberSignature Language="C#" Value="public void LoadGrammar (System.Speech.Recognition.Grammar grammar);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void LoadGrammar(class System.Speech.Recognition.Grammar grammar) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void LoadGrammar(System::Speech::Recognition::Grammar ^ grammar);" />
      <MemberSignature Language="F#" Value="member this.LoadGrammar : System.Speech.Recognition.Grammar -&gt; unit" Usage="speechRecognizer.LoadGrammar grammar" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="grammar" Type="System.Speech.Recognition.Grammar" />
      </Parameters>
      <Docs>
        <param name="grammar">要載入的語音辨識文法。</param>
        <summary>載入語音辨識文法。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 如果已載入，以非同步方式載入時，或無法載入任何辨識器的語音辨識文法共用辨識器，則會擲回例外狀況。 如果辨識器正在執行，應用程式必須使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>暫停之前載入、 卸載、 啟用，或停用文法的語音辨識引擎。  
  
 若要以非同步方式載入語音辨識文法，請使用<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>方法。  
  
   
  
## Examples  
 下列範例是主控台應用程式載入語音辨識文法，並示範非同步模擬的輸入、 相關聯的辨識結果，以及語音辨識器所引發的相關聯的事件的一部分。 如果未執行 Windows 語音辨識，然後啟動此應用程式將也會啟動 Windows 語音辨識。 如果 Windows 語音辨識處於**睡眠**狀態，然後<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>一定會傳回 null。  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call does not match the grammar   
        // or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }   
  
    // Handle the EmulateRecognizeCompleted event.   
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
      </Docs>
    </Member>
    <Member MemberName="LoadGrammarAsync">
      <MemberSignature Language="C#" Value="public void LoadGrammarAsync (System.Speech.Recognition.Grammar grammar);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void LoadGrammarAsync(class System.Speech.Recognition.Grammar grammar) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void LoadGrammarAsync(System::Speech::Recognition::Grammar ^ grammar);" />
      <MemberSignature Language="F#" Value="member this.LoadGrammarAsync : System.Speech.Recognition.Grammar -&gt; unit" Usage="speechRecognizer.LoadGrammarAsync grammar" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="grammar" Type="System.Speech.Recognition.Grammar" />
      </Parameters>
      <Docs>
        <param name="grammar">要載入的語音辨識文法。</param>
        <summary>以非同步方式載入語音辨識文法。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 當辨識器完成這個非同步作業時，會引發<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted>事件。 如果已載入，以非同步方式載入時，或無法載入任何辨識器的語音辨識文法的辨識器，則會擲回例外狀況。 如果辨識器正在執行，應用程式必須使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>暫停之前載入、 卸載、 啟用，或停用文法的語音辨識引擎。  
  
 若要以同步方式載入語音辨識文法，請使用<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>方法。  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted" />
      </Docs>
    </Member>
    <Member MemberName="LoadGrammarCompleted">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; LoadGrammarCompleted;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; LoadGrammarCompleted" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted" />
      <MemberSignature Language="VB.NET" Value="Public Event LoadGrammarCompleted As EventHandler(Of LoadGrammarCompletedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::LoadGrammarCompletedEventArgs ^&gt; ^ LoadGrammarCompleted;" />
      <MemberSignature Language="F#" Value="member this.LoadGrammarCompleted : EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; " Usage="member this.LoadGrammarCompleted : System.EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>在辨識器完成語音辨識文法的非同步載入時發生。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 辨識器<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>方法來啟始非同步作業。 辨識器引發`LoadGrammarCompleted`完成作業時的事件。 若要取得<xref:System.Speech.Recognition.Grammar>物件辨識器載入，請使用<xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A>相關聯的屬性<xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs>。 若要取得目前<xref:System.Speech.Recognition.Grammar>辨識器已載入，物件會使用辨識器<xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A>屬性。  
  
 當您建立的委派`LoadGrammarCompleted`事件，識別即將處理此事件的方法。 若要使事件與您的事件處理常式產生關聯，請將委派的執行個體 (Instance) 加入至事件。 除非您移除委派，否則每當事件發生時就會呼叫事件處理常式。 如需有關事件處理常式委派的詳細資訊，請參閱[事件與委派](https://go.microsoft.com/fwlink/?LinkId=162418)。  
  
   
  
## Examples  
 下列範例會建立共用的語音辨識器，並接著會建立兩種類型的特定單字的辨識和接受免費的聽寫文法。 此範例會以非同步方式載入所有建立的文法，辨識器。 辨識器的處理常式<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted>和<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件都會寫入主控台的文法用來分別執行辨識和文字辨識結果的名稱。  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
        // Add a handler for the LoadGrammarCompleted event.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
        // Add a handler for the SpeechRecognized event.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Add a handler for the StateChanged event.  
        recognizer.StateChanged +=  
          new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
        // Create "yesno" grammar.  
        Choices yesChoices = new Choices(new string[] { "yes", "yup", "yeah}" });  
        SemanticResultValue yesValue =  
            new SemanticResultValue(yesChoices, (bool)true);  
        Choices noChoices = new Choices(new string[] { "no", "nope", "neah" });  
        SemanticResultValue noValue =  
            new SemanticResultValue(noChoices, (bool)false);  
        SemanticResultKey yesNoKey =  
            new SemanticResultKey("yesno", new Choices(new GrammarBuilder[] { yesValue, noValue }));  
        Grammar yesnoGrammar = new Grammar(yesNoKey);  
        yesnoGrammar.Name = "yesNo";  
  
        // Create "done" grammar.  
        Grammar doneGrammar =  
          new Grammar(new Choices(new string[] { "done", "exit", "quit", "stop" }));  
        doneGrammar.Name = "Done";  
  
        // Create dictation grammar.  
        Grammar dictation = new DictationGrammar();  
        dictation.Name = "Dictation";  
  
        // Load grammars to the recognizer.  
        recognizer.LoadGrammarAsync(yesnoGrammar);  
        recognizer.LoadGrammarAsync(doneGrammar);  
        recognizer.LoadGrammarAsync(dictation);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Grammar({0}): {1}", e.Result.Grammar.Name, e.Result.Text);  
  
      // Add event handler code here.  
    }  
  
    // Handle the LoadGrammarCompleted event.   
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
  
        // Add exception handling code here.  
      }  
  
      Console.WriteLine("Grammar {0} {1} loaded.",  
      grammarName, (grammarLoaded) ? "is" : "is not");  
    }  
  
    // Put the shared speech recognizer into "listening" mode.   
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="T:System.Speech.Recognition.LoadGrammarCompletedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
      </Docs>
    </Member>
    <Member MemberName="MaxAlternates">
      <MemberSignature Language="C#" Value="public int MaxAlternates { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 MaxAlternates" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates" />
      <MemberSignature Language="VB.NET" Value="Public Property MaxAlternates As Integer" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property int MaxAlternates { int get(); void set(int value); };" />
      <MemberSignature Language="F#" Value="member this.MaxAlternates : int with get, set" Usage="System.Speech.Recognition.SpeechRecognizer.MaxAlternates" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>取得或設定共用辨識器為每個辨識作業傳回之替代辨識結果的最大數目。</summary>
        <value>語音辨識器為每個辨識作業傳回之替代結果的最大數目。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>的屬性<xref:System.Speech.Recognition.RecognitionResult>類別包含的集合<xref:System.Speech.Recognition.RecognizedPhrase>代表輸入的其他候選解譯的物件。  
  
 預設值為<xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A>為 10。  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Alternates" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="PauseRecognizerOnRecognition">
      <MemberSignature Language="C#" Value="public bool PauseRecognizerOnRecognition { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance bool PauseRecognizerOnRecognition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition" />
      <MemberSignature Language="VB.NET" Value="Public Property PauseRecognizerOnRecognition As Boolean" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property bool PauseRecognizerOnRecognition { bool get(); void set(bool value); };" />
      <MemberSignature Language="F#" Value="member this.PauseRecognizerOnRecognition : bool with get, set" Usage="System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Boolean</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>取得或設定值，這個值表示當應用程式正在處理 <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /> 事件時，共用辨識器是否會暫停辨識作業。</summary>
        <value>如果共用辨識器會在有任何應用程式正在處理 <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /> 事件時等候處理輸入則為 <see langword="true" />，否則為 <see langword="false" />。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 將此屬性設定為`true`，如果內<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>應用程式，就必須變更 語音辨識服務的狀態，或變更 語音辨識服務之前已載入或啟用語音辨識文法的事件處理常式多輸入的處理程序。  
  
> [!NOTE]
>  設定<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>屬性，以`true`會導致每個<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>來封鎖 Windows speech recognition 服務的每個應用程式中的事件處理常式。  
  
 若要變更同步至共用辨識器您的應用程式狀態，請使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>方法。  
  
 當<xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A>已`true`，在執行期間<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>處理常式的語音辨識服務會暫停，並到達時，緩衝處理新的音訊輸入。 一次<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>結束事件處理常式，語音辨識服務繼續辨識並開始處理從輸入緩衝區的資訊。  
  
 若要啟用或停用語音辨識服務，請使用<xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>屬性。  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Enabled" />
      </Docs>
    </Member>
    <Member MemberName="RecognizerAudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan RecognizerAudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan RecognizerAudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property RecognizerAudioPosition As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan RecognizerAudioPosition { TimeSpan get(); };" />
      <MemberSignature Language="F#" Value="member this.RecognizerAudioPosition : TimeSpan" Usage="System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>取得辨識器正在處理的音訊輸入的目前位置。</summary>
        <value>辨識器在其所處理之音訊輸入中的位置。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 `RecognizerAudioPosition`屬性參考中處理其音訊輸入的辨識器的位置。 相較之下，<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>屬性會參考其產生的音訊資料流中的輸入的裝置的位置。 這些位置可能會不同。 比方說，如果辨識器已收到輸入其已不但產生的值就辨識結果<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>屬性是值小於<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>屬性。  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="RecognizerInfo">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizerInfo RecognizerInfo { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.RecognizerInfo RecognizerInfo" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property RecognizerInfo As RecognizerInfo" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::RecognizerInfo ^ RecognizerInfo { System::Speech::Recognition::RecognizerInfo ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.RecognizerInfo : System.Speech.Recognition.RecognizerInfo" Usage="System.Speech.Recognition.SpeechRecognizer.RecognizerInfo" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerInfo</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>取得共用語音辨識器的相關資訊。</summary>
        <value>共用語音辨識器的相關資訊。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 這個屬性會傳回 Windows 語音辨識使用中的語音辨識器的相關資訊。  
  
   
  
## Examples  
 下列範例會將共用辨識器的相關資訊傳送至主控台。  
  
```csharp  
  
using System;  
using System.Speech.Recognition;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        Console.WriteLine("Recognizer information for the shared recognizer:");  
        Console.WriteLine("  Name: {0}", recognizer.RecognizerInfo.Name);  
        Console.WriteLine("  Culture: {0}", recognizer.RecognizerInfo.Culture.ToString());  
        Console.WriteLine("  Description: {0}", recognizer.RecognizerInfo.Description);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerInfo" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.State" />
      </Docs>
    </Member>
    <Member MemberName="RecognizerUpdateReached">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; RecognizerUpdateReached;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; RecognizerUpdateReached" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
      <MemberSignature Language="VB.NET" Value="Public Event RecognizerUpdateReached As EventHandler(Of RecognizerUpdateReachedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::RecognizerUpdateReachedEventArgs ^&gt; ^ RecognizerUpdateReached;" />
      <MemberSignature Language="F#" Value="member this.RecognizerUpdateReached : EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; " Usage="member this.RecognizerUpdateReached : System.EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>在辨識器暫停以同步處理辨識和其他作業時發生。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 應用程式必須使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>若要暫停的執行個體<xref:System.Speech.Recognition.SpeechRecognizer>之前修改其<xref:System.Speech.Recognition.Grammar>物件。 例如，當<xref:System.Speech.Recognition.SpeechRecognizer>會暫停，您可以載入、 卸載、 啟用和停用<xref:System.Speech.Recognition.Grammar>物件。 <xref:System.Speech.Recognition.SpeechRecognizer>時，引發這個事件已準備好接受修改。  
  
 當您建立的委派<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件，識別即將處理此事件的方法。 若要使事件與您的事件處理常式產生關聯，請將委派的執行個體 (Instance) 加入至事件。 除非您移除委派，否則每當事件發生時就會呼叫事件處理常式。 如需有關事件處理常式委派的詳細資訊，請參閱[事件與委派](https://go.microsoft.com/fwlink/?LinkId=162418)。  
  
   
  
## Examples  
 下列範例示範的主控台應用程式載入和卸載<xref:System.Speech.Recognition.Grammar>物件。 應用程式使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>方法來要求語音辨識引擎暫停讓它可以接收更新。 應用程式，然後載入或卸載<xref:System.Speech.Recognition.Grammar>物件。  
  
 在每個更新的處理常式<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件會寫入目前載入的狀態與名稱<xref:System.Speech.Recognition.Grammar>至主控台的物件。 當載入和卸載的文法，應用程式第一次會辨識陣列動物的名稱和伺服器陣列的動物名稱的水果、 名稱然後水果的名稱。  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Collections.Generic;  
using System.Threading;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
      // Create the first grammar - Farm.  
      Choices animals = new Choices(new string[] { "cow", "pig", "goat" });  
      GrammarBuilder farm = new GrammarBuilder(animals);  
      Grammar farmAnimals = new Grammar(farm);  
      farmAnimals.Name = "Farm";  
  
      // Create the second grammar - Fruit.  
      Choices fruit = new Choices(new string[] { "apples", "peaches", "oranges" });  
      GrammarBuilder favorite = new GrammarBuilder(fruit);  
      Grammar favoriteFruit = new Grammar(favorite);  
      favoriteFruit.Name = "Fruit";  
  
      // Attach event handlers.  
      recognizer.SpeechRecognized +=  
        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
      recognizer.RecognizerUpdateReached +=  
        new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  
      recognizer.StateChanged +=   
        new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
      // Load the Farm grammar.  
      recognizer.LoadGrammar(farmAnimals);  
      Console.WriteLine("Grammar Farm is loaded");  
  
      // Pause to recognize farm animals.  
      Thread.Sleep(7000);  
      Console.WriteLine();  
  
      // Request an update and load the Fruit grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.LoadGrammarAsync(favoriteFruit);  
      Thread.Sleep(5000);  
  
      // Request an update and unload the Farm grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.UnloadGrammar(farmAnimals);  
      Thread.Sleep(5000);  
  
      // Keep the console window open.  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Put the shared speech recognizer into "listening" mode.  
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  
    // At the update, get the names and enabled status of the currently loaded grammars.  
    public static void recognizer_RecognizerUpdateReached(  
      object sender, RecognizerUpdateReachedEventArgs e)  
    {  
      Console.WriteLine();  
      Console.WriteLine("Update reached:");  
      Thread.Sleep(1000);  
  
      string qualifier;  
      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
      foreach (Grammar g in grammars)  
      {  
        qualifier = (g.Enabled) ? "enabled" : "disabled";  
        Console.WriteLine("  Grammar {0} is loaded and is {1}.",  
        g.Name, qualifier);  
      }  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("  Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
        <altmember cref="T:System.Speech.Recognition.RecognizerUpdateReachedEventArgs" />
      </Docs>
    </Member>
    <MemberGroup MemberName="RequestRecognizerUpdate">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>要求共用辨識器暫停並更新其狀態。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 使用這個方法將變更同步至共用辨識器。 比方說，如果您載入或卸載語音辨識文法，辨識器正在處理輸入時，使用這個方法和<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>辨識器的狀態與同步處理您的應用程式行為的事件。  
  
 辨識器呼叫這個方法時，會暫停或完成非同步作業，並會產生<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件。 A<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件處理常式然後可以修改辨識作業之間的辨識器的狀態。  
  
 當呼叫這個方法：  
  
-   如果辨識器未處理的輸入，辨識器立即產生<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件。  
  
-   如果辨識器正在處理包含無回應或背景雜音的輸入，辨識器暫停辨識作業，並產生<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件。  
  
-   如果辨識器正在處理不是組成無回應或背景雜訊的輸入，辨識器完成辨識作業，並接著會產生<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件。  
  
 當辨識器正在處理<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件：  
  
-   辨識器不會處理輸入，以及值<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>屬性維持不變。  
  
-   辨識器會繼續收集輸入的值<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>屬性可以變更。  
  
 若要變更共用辨識器會在處理應用程式時，會暫停辨識作業是否<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件，使用<xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A>屬性。  
  
   
  
## Examples  
 下列範例示範的主控台應用程式載入和卸載<xref:System.Speech.Recognition.Grammar>物件。 應用程式使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>方法來要求語音辨識引擎暫停讓它可以接收更新。 應用程式，然後載入或卸載<xref:System.Speech.Recognition.Grammar>物件。  
  
 在每個更新的處理常式<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件會寫入目前載入的狀態與名稱<xref:System.Speech.Recognition.Grammar>至主控台的物件。 當載入和卸載的文法，應用程式第一次會辨識陣列動物的名稱和伺服器陣列的動物名稱的水果、 名稱然後水果的名稱。  
  
```csharp  
  
using System;  
using System.Speech.Recognition;  
using System.Collections.Generic;  
using System.Threading;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize an in-process speech recognition engine and configure its input.  
      recognizer = new SpeechRecognizer();  
  
      // Create the first grammar - Farm.  
      Choices animals = new Choices(new string[] { "cow", "pig", "goat" });  
      GrammarBuilder farm = new GrammarBuilder(animals);  
      Grammar farmAnimals = new Grammar(farm);  
      farmAnimals.Name = "Farm";  
  
      // Create the second grammar - Fruit.  
      Choices fruit = new Choices(new string[] { "apples", "peaches", "oranges" });  
      GrammarBuilder favorite = new GrammarBuilder(fruit);  
      Grammar favoriteFruit = new Grammar(favorite);  
      favoriteFruit.Name = "Fruit";  
  
      // Attach event handlers.  
      recognizer.SpeechRecognized +=  
        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
      recognizer.RecognizerUpdateReached +=  
        new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  
  
      // Check to see if recognizer is loaded, wait if it is not loaded.  
      if (recognizer.State != RecognizerState.Listening)  
      {  
        Thread.Sleep(5000);  
  
        // Put recognizer in listening state.  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
  
      // Load the Farm grammar.  
      recognizer.LoadGrammar(farmAnimals);  
      Console.WriteLine("Grammar Farm is loaded");  
  
      // Pause to recognize farm animals.  
      Thread.Sleep(7000);  
      Console.WriteLine();  
  
      // Request an update and load the Fruit grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.LoadGrammarAsync(favoriteFruit);  
      Thread.Sleep(5000);  
  
      // Request an update and unload the Farm grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.UnloadGrammar(farmAnimals);  
      Thread.Sleep(5000);  
  
      // Keep the console window open.  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    public static void recognizer_RecognizerUpdateReached(object sender, RecognizerUpdateReachedEventArgs e)  
    {  
      // At the update, get the names and enabled status of the currently loaded grammars.  
      Console.WriteLine();  
      Console.WriteLine("Update reached:");  
      Thread.Sleep(1000);  
      string qualifier;  
      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
      foreach (Grammar g in grammars)  
      {  
        qualifier = (g.Enabled) ? "enabled" : "disabled";  
        Console.WriteLine("  Grammar {0} is loaded and is {1}.",  
        g.Name, qualifier);  
      }  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("  Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
      </Docs>
    </MemberGroup>
    <Member MemberName="RequestRecognizerUpdate">
      <MemberSignature Language="C#" Value="public void RequestRecognizerUpdate ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RequestRecognizerUpdate() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
      <MemberSignature Language="VB.NET" Value="Public Sub RequestRecognizerUpdate ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RequestRecognizerUpdate();" />
      <MemberSignature Language="F#" Value="member this.RequestRecognizerUpdate : unit -&gt; unit" Usage="speechRecognizer.RequestRecognizerUpdate " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>要求共用辨識器暫停並更新其狀態。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 當辨識器會產生<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件，<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>屬性<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>是`null`。  
  
 若要提供的使用者語彙基元，請使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>或<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>方法。 若要指定的音訊位置的位移，請使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>方法。  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="RequestRecognizerUpdate">
      <MemberSignature Language="C#" Value="public void RequestRecognizerUpdate (object userToken);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RequestRecognizerUpdate(object userToken) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)" />
      <MemberSignature Language="VB.NET" Value="Public Sub RequestRecognizerUpdate (userToken As Object)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RequestRecognizerUpdate(System::Object ^ userToken);" />
      <MemberSignature Language="F#" Value="member this.RequestRecognizerUpdate : obj -&gt; unit" Usage="speechRecognizer.RequestRecognizerUpdate userToken" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="userToken" Type="System.Object" />
      </Parameters>
      <Docs>
        <param name="userToken">使用者定義的資訊，包含該作業的資訊。</param>
        <summary>要求共用辨識器暫停並更新其狀態，以及提供相關聯事件的使用者語彙基元。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 當辨識器會產生<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件，<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>屬性<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>包含的值`userToken`參數。  
  
 若要指定的音訊位置的位移，請使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>方法。  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="RequestRecognizerUpdate">
      <MemberSignature Language="C#" Value="public void RequestRecognizerUpdate (object userToken, TimeSpan audioPositionAheadToRaiseUpdate);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RequestRecognizerUpdate(object userToken, valuetype System.TimeSpan audioPositionAheadToRaiseUpdate) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)" />
      <MemberSignature Language="VB.NET" Value="Public Sub RequestRecognizerUpdate (userToken As Object, audioPositionAheadToRaiseUpdate As TimeSpan)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RequestRecognizerUpdate(System::Object ^ userToken, TimeSpan audioPositionAheadToRaiseUpdate);" />
      <MemberSignature Language="F#" Value="member this.RequestRecognizerUpdate : obj * TimeSpan -&gt; unit" Usage="speechRecognizer.RequestRecognizerUpdate (userToken, audioPositionAheadToRaiseUpdate)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="userToken" Type="System.Object" />
        <Parameter Name="audioPositionAheadToRaiseUpdate" Type="System.TimeSpan" />
      </Parameters>
      <Docs>
        <param name="userToken">使用者定義的資訊，包含該作業的資訊。</param>
        <param name="audioPositionAheadToRaiseUpdate">從目前的 <see cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" /> 起將要求延遲的位移。</param>
        <summary>要求共用辨識器暫停並更新其狀態，以及提供相關聯事件的位移和使用者語彙基元。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 辨識器，不會啟動在辨識器的更新要求辨識器直到<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>等於目前<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>再加上值`audioPositionAheadToRaiseUpdate`參數。  
  
 當辨識器會產生<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件，<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>屬性<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>包含的值`userToken`參數。  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="SpeechDetected">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt; SpeechDetected;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechDetectedEventArgs&gt; SpeechDetected" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
      <MemberSignature Language="VB.NET" Value="Public Event SpeechDetected As EventHandler(Of SpeechDetectedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechDetectedEventArgs ^&gt; ^ SpeechDetected;" />
      <MemberSignature Language="F#" Value="member this.SpeechDetected : EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt; " Usage="member this.SpeechDetected : System.EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>當辨識器偵測到可辨識為語音的輸入時發生。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 共用辨識器可以引發以回應輸入此事件。 <xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A>相關聯的屬性<xref:System.Speech.Recognition.SpeechDetectedEventArgs>物件表示在辨識器偵測到的語音位置的輸入資料流中的位置。 如需詳細資訊，請參閱<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>並<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>屬性並<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>和<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>方法。  
  
 當您建立的委派<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>事件，識別即將處理此事件的方法。 若要使事件與您的事件處理常式產生關聯，請將委派的執行個體 (Instance) 加入至事件。 除非您移除委派，否則每當事件發生時就會呼叫事件處理常式。 如需有關事件處理常式委派的詳細資訊，請參閱[事件與委派](https://go.microsoft.com/fwlink/?LinkId=162418)。  
  
   
  
## Examples  
 下列範例是主控台應用程式選擇的班機的來源和目的地城市的一部分。 應用程式會辨識片語，例如 「 我想要從邁阿密飛抵芝加哥 」。  此範例會使用<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>事件以報告<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>偵測到每個時間語音。  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer =  
         new SpeechRecognizer())  
      {  
  
        // Create a grammar.  
        Choices cities = new Choices(new string[] {   
          "Los Angeles", "New York", "Chicago", "San Francisco", "Miami", "Dallas" });  
  
        GrammarBuilder gb = new GrammarBuilder();  
        gb.Append("I would like to fly from");  
        gb.Append(cities);  
        gb.Append("to");  
        gb.Append(cities);  
  
        // Create a Grammar object and load it to the recognizer.  
        Grammar g = new Grammar(gb);  
        g.Name = ("City Chooser");  
        recognizer.LoadGrammarAsync(g);  
  
        // Attach event handlers.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
        recognizer.SpeechDetected +=   
          new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the SpeechDetected event.  
    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  
    {  
      Console.WriteLine("Speech detected at AudioPosition = {0}", e.AudioPosition);  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechDetectedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="SpeechHypothesized">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; SpeechHypothesized;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; SpeechHypothesized" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event SpeechHypothesized As EventHandler(Of SpeechHypothesizedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechHypothesizedEventArgs ^&gt; ^ SpeechHypothesized;" />
      <MemberSignature Language="F#" Value="member this.SpeechHypothesized : EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; " Usage="member this.SpeechHypothesized : System.EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>在辨識器已辨識的文字可能是文法中多個完整片語的元件時發生。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 共用辨識器可以引發這個事件，當輸入是模稜兩可。 例如語音辨識文法支援的辨識 」 新遊戲請 」 或 「 新遊戲"，"新遊戲請 」 是模稜兩可的輸入，而 「 新遊戲 」 是模稜兩可的輸入。  
  
 當您建立的委派<xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>事件，識別即將處理此事件的方法。 若要使事件與您的事件處理常式產生關聯，請將委派的執行個體 (Instance) 加入至事件。 除非您移除委派，否則每當事件發生時就會呼叫事件處理常式。 如需有關事件處理常式委派的詳細資訊，請參閱[事件與委派](https://go.microsoft.com/fwlink/?LinkId=162418)。  
  
   
  
## Examples  
 下列範例會辨識片語，例如 「 顯示爵士的類別目錄中的演出者的清單 」。 此範例會使用<xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>事件，以在主控台顯示不完整的片語片段，因為它們會被辨識。  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer =  
         new SpeechRecognizer())  
      {  
  
        // Create a grammar.  
        //  Create lists of alternative choices.  
        Choices listTypes = new Choices(new string[] { "albums", "artists" });  
        Choices genres = new Choices(new string[] {   
          "blues", "classical", "gospel", "jazz", "rock" });  
  
        //  Create a GrammarBuilder object and assemble the grammar components.  
        GrammarBuilder mediaMenu = new GrammarBuilder("Display the list of");  
        mediaMenu.Append(listTypes);  
        mediaMenu.Append("in the");  
        mediaMenu.Append(genres);  
        mediaMenu.Append("category.");  
  
        //  Build a Grammar object from the GrammarBuilder.  
        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  
        mediaMenuGrammar.Name = "Media Chooser";  
  
        // Attach event handlers.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.SpeechHypothesized +=   
          new EventHandler<SpeechHypothesizedEventArgs>(recognizer_SpeechHypothesized);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(mediaMenuGrammar);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the SpeechHypothesized event.  
    static void recognizer_SpeechHypothesized(object sender, SpeechHypothesizedEventArgs e)  
    {  
      Console.WriteLine("Speech hypothesized: " + e.Result.Text);  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechHypothesizedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="SpeechRecognitionRejected">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; SpeechRecognitionRejected;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; SpeechRecognitionRejected" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
      <MemberSignature Language="VB.NET" Value="Public Event SpeechRecognitionRejected As EventHandler(Of SpeechRecognitionRejectedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechRecognitionRejectedEventArgs ^&gt; ^ SpeechRecognitionRejected;" />
      <MemberSignature Language="F#" Value="member this.SpeechRecognitionRejected : EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; " Usage="member this.SpeechRecognitionRejected : System.EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>當辨識器接收到不符合任何已載入的語音辨識文法的輸入時發生。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 如果經判定，輸入不符合足夠的信心與任何已載入的語音辨識文法的共用辨識器就會引發此事件。 <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>的屬性<xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>包含 已拒絕<xref:System.Speech.Recognition.RecognitionResult>物件。  
  
 共用辨識器所管理的信賴度臨界值<xref:System.Speech.Recognition.SpeechRecognizer>是使用者設定檔相關聯，儲存在 Windows 登錄中。 應用程式不應該寫入登錄中的共用辨識器的屬性變更。  
  
 當您建立的委派<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>事件，識別即將處理此事件的方法。 若要使事件與您的事件處理常式產生關聯，請將委派的執行個體 (Instance) 加入至事件。 除非您移除委派，否則每當事件發生時就會呼叫事件處理常式。 如需有關事件處理常式委派的詳細資訊，請參閱[事件與委派](https://go.microsoft.com/fwlink/?LinkId=162418)。  
  
   
  
## Examples  
 下列範例會辨識片語這類 「 爵士的類別目錄中顯示演出者的清單 」 或 「 顯示專輯 gospel 」。 此範例會使用的處理常式<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>語音輸入不能有足夠的信心，來產生成功辨識比對的文法中的內容時，請在主控台中顯示通知的事件。  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer =  
         new SpeechRecognizer())  
      {  
  
        // Create a grammar.  
        //  Create lists of alternative choices.  
        Choices listTypes = new Choices(new string[] { "albums", "artists" });  
        Choices genres = new Choices(new string[] {   
          "blues", "classical", "gospel", "jazz", "rock" });  
  
        //  Create a GrammarBuilder object and assemble the grammar components.  
        GrammarBuilder mediaMenu = new GrammarBuilder("Display");  
        mediaMenu.Append("the list of", 0, 1);  
        mediaMenu.Append(listTypes);  
        mediaMenu.Append("in the", 0, 1);  
        mediaMenu.Append(genres);  
        mediaMenu.Append("category", 0, 1);  
  
        //  Build a Grammar object from the GrammarBuilder.  
        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  
        mediaMenuGrammar.Name = "Media Chooser";  
  
        // Attach event handlers.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.SpeechRecognitionRejected +=   
          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(mediaMenuGrammar);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the SpeechRecognitionRejected event.  
    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  
    {  
      Console.WriteLine("Speech input was rejected.");  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="SpeechRecognized">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt; SpeechRecognized;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechRecognizedEventArgs&gt; SpeechRecognized" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      <MemberSignature Language="VB.NET" Value="Public Event SpeechRecognized As EventHandler(Of SpeechRecognizedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechRecognizedEventArgs ^&gt; ^ SpeechRecognized;" />
      <MemberSignature Language="F#" Value="member this.SpeechRecognized : EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt; " Usage="member this.SpeechRecognized : System.EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>當辨識器接收到符合其中一個語音辨識文法的輸入時發生。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 辨識器引發`SpeechRecognized`事件，如果它決定有足夠的信心，輸入符合其中一個已載入且已啟用的語音辨識文法。 <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>的屬性<xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>包含接受<xref:System.Speech.Recognition.RecognitionResult>物件。  
  
 共用辨識器所管理的信賴度臨界值<xref:System.Speech.Recognition.SpeechRecognizer>是使用者設定檔相關聯，儲存在 Windows 登錄中。 應用程式不應該寫入登錄中的共用辨識器的屬性變更。  
  
 當辨識器接收到符合的文法的輸入<xref:System.Speech.Recognition.Grammar>物件可以引發<xref:System.Speech.Recognition.Grammar.SpeechRecognized>事件。 <xref:System.Speech.Recognition.Grammar>物件的<xref:System.Speech.Recognition.Grammar.SpeechRecognized>就會引發事件之前的語音辨識器<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件。  
  
 當您建立的委派<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件，識別即將處理此事件的方法。 若要使事件與您的事件處理常式產生關聯，請將委派的執行個體 (Instance) 加入至事件。 除非您移除委派，否則每當事件發生時就會呼叫事件處理常式。 如需有關事件處理常式委派的詳細資訊，請參閱[事件與委派](https://go.microsoft.com/fwlink/?LinkId=162418)。  
  
   
  
## Examples  
 下列範例是主控台應用程式載入語音辨識文法及示範共用辨識器、 相關聯的辨識結果，以及語音辨識器所引發的相關聯的事件的語音輸入的一部分。 如果未執行 Windows 語音辨識，然後啟動此應用程式將也會啟動 Windows 語音辨識。  
  
 語音輸入，例如 「 我想要從芝加哥飛到邁阿密 」 將會觸發<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件。 說到片語 「 飛我從休士頓對芝加哥 」 不會觸發<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件。  
  
 此範例會使用的處理常式<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件，以顯示已成功辨識片語和它們包含在主控台中的語意。  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
  
        // Create SemanticResultValue objects that contain cities and airport codes.  
        SemanticResultValue chicago = new SemanticResultValue("Chicago", "ORD");  
        SemanticResultValue boston = new SemanticResultValue("Boston", "BOS");  
        SemanticResultValue miami = new SemanticResultValue("Miami", "MIA");  
        SemanticResultValue dallas = new SemanticResultValue("Dallas", "DFW");  
  
        // Create a Choices object and add the SemanticResultValue objects, using  
        // implicit conversion from SemanticResultValue to GrammarBuilder  
        Choices cities = new Choices();  
        cities.Add(new Choices(new GrammarBuilder[] { chicago, boston, miami, dallas }));  
  
        // Build the phrase and add SemanticResultKeys.  
        GrammarBuilder chooseCities = new GrammarBuilder();  
        chooseCities.Append("I want to fly from");  
        chooseCities.Append(new SemanticResultKey("origin", cities));  
        chooseCities.Append("to");  
        chooseCities.Append(new SemanticResultKey("destination", cities));  
  
        // Build a Grammar object from the GrammarBuilder.  
        Grammar bookFlight = new Grammar(chooseCities);  
        bookFlight.Name = "Book Flight";  
  
        // Add a handler for the LoadGrammarCompleted event.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
        // Add a handler for the SpeechRecognized event.  
        recognizer.SpeechRecognized +=   
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(bookFlight);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
      Console.WriteLine();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized:  " + e.Result.Text);  
      Console.WriteLine();  
      Console.WriteLine("Semantic results:");  
      Console.WriteLine("  The flight origin is " + e.Result.Semantics["origin"].Value);  
      Console.WriteLine("  The flight destination is " + e.Result.Semantics["destination"].Value);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognizedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
      </Docs>
    </Member>
    <Member MemberName="State">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizerState State { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Speech.Recognition.RecognizerState State" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.State" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property State As RecognizerState" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::RecognizerState State { System::Speech::Recognition::RecognizerState get(); };" />
      <MemberSignature Language="F#" Value="member this.State : System.Speech.Recognition.RecognizerState" Usage="System.Speech.Recognition.SpeechRecognizer.State" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerState</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>取得 <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 物件的狀態。</summary>
        <value><see langword="SpeechRecognizer" /> 物件的狀態。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 這個唯讀屬性會指出共用辨識器停留在 Windows 中處於`Stopped`或`Listening`狀態。 如需詳細資訊，請參閱 <xref:System.Speech.Recognition.RecognizerState> 列舉。  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerState" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.StateChanged" />
      </Docs>
    </Member>
    <Member MemberName="StateChanged">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.StateChangedEventArgs&gt; StateChanged;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.StateChangedEventArgs&gt; StateChanged" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.StateChanged" />
      <MemberSignature Language="VB.NET" Value="Public Event StateChanged As EventHandler(Of StateChangedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::StateChangedEventArgs ^&gt; ^ StateChanged;" />
      <MemberSignature Language="F#" Value="member this.StateChanged : EventHandler&lt;System.Speech.Recognition.StateChangedEventArgs&gt; " Usage="member this.StateChanged : System.EventHandler&lt;System.Speech.Recognition.StateChangedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.StateChangedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>當 Windows 桌面語音技術辨識引擎的執行狀態變更時發生。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 共用辨識器時，引發這個事件的 Windows 語音辨識的狀態變更為<xref:System.Speech.Recognition.RecognizerState.Listening>或<xref:System.Speech.Recognition.RecognizerState.Stopped>狀態。  
  
 若要取得共用辨識器的狀態事件時，請使用<xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A>相關聯的屬性<xref:System.Speech.Recognition.StateChangedEventArgs>。 若要取得共用辨識器的目前狀態，請使用 辨識器<xref:System.Speech.Recognition.SpeechRecognizer.State%2A>屬性。  
  
 當您建立的委派<xref:System.Speech.Recognition.SpeechRecognizer.StateChanged>事件，識別即將處理此事件的方法。 若要使事件與您的事件處理常式產生關聯，請將委派的執行個體 (Instance) 加入至事件。 除非您移除委派，否則每當事件發生時就會呼叫事件處理常式。 如需有關事件處理常式委派的詳細資訊，請參閱[事件與委派](https://go.microsoft.com/fwlink/?LinkId=162418)。  
  
   
  
## Examples  
 下列範例會建立共用的語音辨識器，並接著會建立兩種類型的特定單字的辨識和接受免費的聽寫文法。 此範例會以非同步方式載入所有建立的文法，辨識器。  處理常式<xref:System.Speech.Recognition.SpeechRecognizer.StateChanged>事件會使用<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>把 Windows 辨識 「 接聽 」 模式的方法。  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
      // Add a handler for the LoadGrammarCompleted event.  
      recognizer.LoadGrammarCompleted += new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
      // Add a handler for the SpeechRecognized event.  
      recognizer.SpeechRecognized += new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
      // Add a handler for the StateChanged event.  
      recognizer.StateChanged += new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
      // Create "yesno" grammar.  
      Choices yesChoices = new Choices(new string[] { "yes", "yup", "yah}" });  
      SemanticResultValue yesValue =  
          new SemanticResultValue(yesChoices, (bool)true);  
      Choices noChoices = new Choices(new string[] { "no", "nope", "nah" });  
      SemanticResultValue noValue = new SemanticResultValue(noChoices, (bool)false);  
      SemanticResultKey yesNoKey =  
          new SemanticResultKey("yesno", new Choices(new GrammarBuilder[] { yesValue, noValue }));  
      Grammar yesnoGrammar = new Grammar(yesNoKey);  
      yesnoGrammar.Name = "yesNo";  
  
      // Create "done" grammar.  
      Grammar doneGrammar =  
        new Grammar(new Choices(new string[] { "done", "exit", "quit", "stop" }));  
      doneGrammar.Name = "Done";  
  
      // Create dictation grammar.  
      Grammar dictation = new DictationGrammar();  
      dictation.Name = "Dictation";  
  
      // Load grammars to the recognizer.  
      recognizer.LoadGrammarAsync(yesnoGrammar);  
      recognizer.LoadGrammarAsync(doneGrammar);  
      recognizer.LoadGrammarAsync(dictation);  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Put the shared speech recognizer into "listening" mode.  
    static void  recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
     if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void  recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
     Console.WriteLine("Grammar({0}): {1}", e.Result.Grammar.Name, e.Result.Text);  
  
      // Add event handler code here.  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void  recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
     string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
      }  
  
      // Add exception handling code here.  
      Console.WriteLine("Grammar {0} {1} loaded.",  
      grammarName, (grammarLoaded) ? "is" : "is not");  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerState" />
        <altmember cref="T:System.Speech.Recognition.StateChangedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.State" />
      </Docs>
    </Member>
    <Member MemberName="UnloadAllGrammars">
      <MemberSignature Language="C#" Value="public void UnloadAllGrammars ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void UnloadAllGrammars() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
      <MemberSignature Language="VB.NET" Value="Public Sub UnloadAllGrammars ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void UnloadAllGrammars();" />
      <MemberSignature Language="F#" Value="member this.UnloadAllGrammars : unit -&gt; unit" Usage="speechRecognizer.UnloadAllGrammars " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>從共用辨識器卸載所有語音辨識文法。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 如果辨識器正在以非同步方式載入文法，這個方法會等候直到載入文法之前它會卸載所有的辨識器的文法。  
  
 若要卸除特定的文法，請使用<xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A>方法。  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
      </Docs>
    </Member>
    <Member MemberName="UnloadGrammar">
      <MemberSignature Language="C#" Value="public void UnloadGrammar (System.Speech.Recognition.Grammar grammar);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void UnloadGrammar(class System.Speech.Recognition.Grammar grammar) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void UnloadGrammar(System::Speech::Recognition::Grammar ^ grammar);" />
      <MemberSignature Language="F#" Value="member this.UnloadGrammar : System.Speech.Recognition.Grammar -&gt; unit" Usage="speechRecognizer.UnloadGrammar grammar" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="grammar" Type="System.Speech.Recognition.Grammar" />
      </Parameters>
      <Docs>
        <param name="grammar">要卸載的文法。</param>
        <summary>從共用辨識器卸載指定的語音辨識文法。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 如果辨識器正在執行，應用程式必須使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>暫停之前載入、 卸載、 啟用，或停用文法的語音辨識引擎。 若要卸除所有文法，請使用<xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A>方法。  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
      </Docs>
    </Member>
  </Members>
</Type>